{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee44ab3",
   "metadata": {},
   "source": [
    "## Extension: Grid World\n",
    "\n",
    "Consider a robot navigating in a grid-based environment. Each cell in the grid represents a distinct state of the surroundings. The robot can take four deterministic actions at each cell: \"up,\" \"down,\" \"left,\" and \"right,\" resulting in the robot to move precisely one cell in the corresponding direction on the grid. Actions that would take the agent off the grid are not allowed. Within the grid, certain states (orange) correspond to undesirable conditions, such as rough terrain, while one state (green) represents the ultimate goal.\n",
    "\n",
    "Upon reaching the goal state, the robot gains a reward of 1. Conversely, traversing the rough terrain incurs a penalty (or negative reward) of 10. Additionally, every move the robot makes entails a penalty of 1. The robot's primary objective is to efficiently reach the goal state, aiming to maximize the total reward (minimize the total penalty) incurred. This entails both avoiding the rough terrain and efficiently navigating through the grid.\n",
    "\n",
    "<img src=\"grid_world.png\" alt=\"Image\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285a969-d9b8-465b-9041-a280de02647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c89c6",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Try to utilize dynamic programming algorithm to address the grid world problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c925b",
   "metadata": {},
   "source": [
    "### Q2\n",
    "What challenge or issue are you currently facing? Provide an explanation for the nature of this problem. In Practical 4, we will explore strategies to address this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2bcaa",
   "metadata": {},
   "source": [
    "< Answer Here >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7079286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid world as a matrix using np.array. Each entry correspond to its reward.\n",
    "grid = np.array([\n",
    "    [0, 0, -10, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, -10, 0],\n",
    "    [0, 0, -10, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the value function as a zero matrix with the same shape with the grid.\n",
    "values = np.zeros_like(grid, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to get next state. The action includes \"up\", \"down\", \"left\", \"right\".\n",
    "def get_next_state(i, j, action):\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ea551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to check if the next state is valid. The states beyond the grid are not valid. This function returns Boolean value.\n",
    "def is_valid_state(i, j, grid):\n",
    "    rows, cols = grid.shape\n",
    "    return 0 <= i < rows and 0 <= j < cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
